---
title: More complex models for analyzing flight data
author: John Johnson
date: '2018-02-19'
slug: more-complex-models-for-analyzing-flight-data
categories:
  - Greenville
tags:
  - Bayesian
  - flights
  - Stan
draft: true
---



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In previous posts on Stan, we examined a dataset of flight departures from GSP international airport. We fit and interpreted a very simple model (simple mean plus random variation). We discussed one (very poor) way to set a prior distribution on this mean, but we hedged our bets by putting a very wide standard deviation on that prior. Then we examined the output from Stan to start discussing diagnostics. Because our model was simple, the diagnostics looked pretty good, but going forward we need to be on the lookout for issues.</p>
<p>In this post, we will extend the simple mean model to look at factors that might influence the number of flights. We start with the weekday - this is reasonable because the nature of travel is different on the weekend and during the week. We then add in the quarter (e.g. Jan-Mar is Q1, Apr-Jun is Q2). This turns out to be a lot like the analysis of variance (ANOVA) and other general linear models (GLM).</p>
<!--more-->
</div>
<div id="setup-and-data" class="section level1">
<h1>Setup and data</h1>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(rstan)
library(bayesplot)
load(&quot;airline_data.RData&quot;)
airline_data %&gt;% 
  mutate(date=ymd(YEAR*10000+MONTH*100+DAY_OF_MONTH),
         wnum = floor((date - ymd(YEAR*10000+0101))/7)) -&gt; 
  airline_data

airline_data %&gt;% 
  filter(ORIGIN_AIRPORT_ID==11996) %&gt;% 
  count(date) -&gt; 
  counts_depart</code></pre>
<pre class="r"><code>options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)</code></pre>
</div>
<div id="analysis" class="section level1">
<h1>Analysis</h1>
<p>Let’s go back to the raw data for a minute.</p>
<pre class="r"><code>counts_depart %&gt;% 
  ggplot(aes(date,n)) +
  geom_line() +
  scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b %y&quot;) +
  ylab(&quot;Number of departing flights&quot;) +
  xlab(&quot;&quot;)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/load_data-1.png" width="672" /></p>
<p>The flight count data clearly don’t “wiggle around” a constant number the whole year, but rather seem to have a complicated structure. Here’s where domain knowledge can come in handy. There are two patterns: a “high-frequency” (here, weekly) and a “low-frequency” one (here, yearly). We start with the model we had before and keep adding to it.</p>
<div id="adding-a-new-mean-for-each-quarter" class="section level2">
<h2>Adding a new mean for each quarter</h2>
<p>Let’s review the Stan code from before:</p>
<pre><code>data {
  int ndates;
  vector[ndates] flights;
}

parameters {
  real mu;
  real&lt;lower=0&gt; sigma;
}

model {
  flights ~ normal(mu,sigma);
  mu ~ normal(32,10);
  sigma ~ uniform(0,20);
}</code></pre>
<p>The <code>model</code> statement, which connects our <code>parameters</code> to our number of flights, will clearly need to be extended. We start with the <code>flights ~ normal(mu,sigma)</code> statement. We are now saying that the number of flights is affected by more things, like day of week and quarter. So let’s keep it simple for now and only add quarter; say that <code>flights ~ normal(qtr_effect,sigma)</code>. Note we eliminate <code>mu</code> altogether. I had actually kept it in a previous iteration, but got something that didn’t make a lot of sense. Why do you think that might be?</p>
<p>Now there are 4 quarters, so <code>qtr_effect</code> really needs to be a vector with 4 entries. So let’s try again, on the whole Stan code:</p>
<pre><code>data {
  int ndates;
  vector[ndates] flights;
}

parameters {
  real&lt;lower=0&gt; sigma;
  vector[4] qtr_effect;
}

model {
  flights ~ normal(qtr_effect[qtr],sigma);
  sigma ~ uniform(0,20);
}</code></pre>
<p>We’re almost there. We defined a vector of length 4 with our quarter effectin our <code>parameters</code> block, and we implemented an index for <code>qtr_effect</code> in the <code>model</code> block. We need to put a prior on our quarter effects, which we do with a <code>for</code> statement. For ease, we will assume the same prior on each, a normal with mean 0 and sigma of 10. The last thing we need to add is this <code>qtr</code> bit we added, which now has to map the day corresponding to the number of flights to an integer between 1 and 4 (so it can index qtr_effect). As we pass in number of flights as data, so must we pass in this mapping as data. So our final Stan code for number of flights accounting for quarter looks as follows:</p>
<pre><code>data {
  int ndates;
  vector[ndates] flights;
  int qtr[ndates];
}

parameters {
  real&lt;lower=0&gt; sigma;
  vector[4] qtr_effect;
}

model {
  flights ~ normal(qtr_effect[qtr],sigma);
  sigma ~ uniform(0,20);
  for (i in 1:4)
    qtr_effect[i] ~ normal(32,10);
}</code></pre>
<p>Why we represent continuous vectors as <code>vector[length] varname</code> and integer vectors as <code>integer varname[length]</code> I don’t quite get yet. But we’re done with the Stan code. I opened a text file and saved the above as <code>flights_qtr.stan</code>, to be called below.</p>
<p>Now we can proceed as the first post in this series, except now we need to define this <code>qtr</code> vector as the number of the quarter (from 1 to 4) that corresponds to each date and pass it to Stan. The <code>lubridate</code> package can make quick work of this. Remember to update <code>data_to_pass</code> and the file name of the Stan file.</p>
<pre class="r"><code>ndates &lt;- nrow(counts_depart)
flights &lt;- counts_depart$n
qtr &lt;- quarter(counts_depart$date)

data_to_pass &lt;- c(&quot;ndates&quot;,&quot;flights&quot;,&quot;qtr&quot;)
qtr_model_fit &lt;- stan(&quot;flights_qtr.stan&quot;,data=data_to_pass)
save(qtr_model_fit,file=&quot;qtr_model_fit.RData&quot;)</code></pre>
</div>
<div id="analysis-1" class="section level2">
<h2>Analysis</h2>
<p>As before, we examine the printout from <code>qtr_model_fit</code>:</p>
<pre class="r"><code>qtr_model_fit</code></pre>
<pre><code>## Inference for Stan model: flights_qtr.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                  mean se_mean   sd    2.5%     25%     50%     75%   97.5%
## sigma            3.13    0.00 0.12    2.90    3.05    3.13    3.20    3.36
## qtr_effect[1]   13.87    0.01 0.33   13.22   13.65   13.87   14.09   14.50
## qtr_effect[2]   20.20    0.01 0.33   19.57   19.98   20.20   20.42   20.86
## qtr_effect[3]   17.72    0.01 0.39   16.94   17.45   17.73   17.98   18.48
## qtr_effect[4]   17.52    0.01 0.34   16.84   17.29   17.52   17.75   18.18
## lp__          -553.95    0.03 1.57 -557.72 -554.82 -553.66 -552.75 -551.84
##               n_eff Rhat
## sigma          4000    1
## qtr_effect[1]  4000    1
## qtr_effect[2]  4000    1
## qtr_effect[3]  4000    1
## qtr_effect[4]  4000    1
## lp__           2244    1
## 
## Samples were drawn using NUTS(diag_e) at Mon Feb 05 09:51:48 2018.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>As we did last time, we look at traceplots before saying too much more. (Note also that <code>Rhat=1</code> for each of the parameters above, so that looks pretty good.) Because we have a vector, and it would be a pain in the hindside to type out all of the <code>qtr_effect[1] ... qtr_effect[4]</code> parameters, we use the <code>regex_pars</code> option of <code>mcmc_trace</code> to examine the trace plots.</p>
<pre class="r"><code>p &lt;- mcmc_trace(as.array(qtr_model_fit),pars=&quot;sigma&quot;,regex_pars = &quot;qtr_effect&quot;,
                facet_args = list(nrow = 5, labeller = label_parsed))
p</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/traceplot-1.png" width="672" /></p>
<p>Things look pretty good, so we can proceed. We look at density plots as well, with the same bit of trickery with <code>regex_pars</code> as above:</p>
<pre class="r"><code>p &lt;- mcmc_areas(as.matrix(qtr_model_fit),pars=&quot;sigma&quot;,regex_pars = &quot;qtr_effect&quot;,prob = 0.5) +
  ggtitle(&quot;Posterior distributions with medians and 50% intervals&quot;)
p</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/densityplot-1.png" width="672" /></p>
<p>Now we can plainly see that in Quarter 2, the number of flights is much higher, averaging around 20 departures per day (perhaps due to all the summer vacations), with a pullback in Quarters 3 and 4, and with a lot less in Quarter 1.</p>
</div>
</div>
<div id="adding-a-second-explanatory-variable" class="section level1">
<h1>Adding a second explanatory variable</h1>
<p>Using the same reasoning as above, we can add a weekday effect. It would be instructive to work your way through the reasoning, so I present the final Stan code here. (Hint: I started with the <code>flights ~</code> statement in the <code>model</code> block to start the addition.)</p>
<pre><code>data {
  int ndates;
  vector[ndates] flights;
  int qtr[ndates];
  int dow[ndates];
}

parameters {
  real&lt;lower=0&gt; sigma;
  vector[4] qtr_effect;
  vector[7] dow_effect;
}

model {
  flights ~ normal(qtr_effect[qtr] + dow_effect[dow],sigma);
  sigma ~ uniform(0,20);
  for (i in 1:4)
    qtr_effect[i] ~ normal(32,10);
  for (i in 1:7)
    dow_effect[i] ~ normal(0,10);
}</code></pre>
<p>And here is the updated R code to call the new model:</p>
<pre class="r"><code>ndates &lt;- nrow(counts_depart)
flights &lt;- counts_depart$n
qtr &lt;- quarter(counts_depart$date)
dow &lt;- wday(counts_depart$date)

data_to_pass &lt;- c(&quot;ndates&quot;,&quot;flights&quot;,&quot;qtr&quot;,&quot;dow&quot;)
qtr_dow_model_fit &lt;- stan(&quot;flights_qtr_dow.stan&quot;,data=data_to_pass)
save(qtr_dow_model_fit,file=&quot;qtr_dow_model_fit.RData&quot;)
qtr_dow_model_fit</code></pre>
<pre><code>## Inference for Stan model: flights_qtr_dow.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                  mean se_mean   sd    2.5%     25%     50%     75%   97.5%
## sigma            2.28    0.00 0.09    2.12    2.22    2.28    2.34    2.47
## qtr_effect[1]   19.31    0.22 2.88   13.15   17.55   19.22   21.18   24.92
## qtr_effect[2]   25.70    0.22 2.88   19.57   23.97   25.60   27.57   31.33
## qtr_effect[3]   23.25    0.22 2.89   17.16   21.48   23.15   25.17   28.89
## qtr_effect[4]   23.07    0.22 2.88   16.86   21.29   22.96   24.93   28.64
## dow_effect[1]   -6.32    0.22 2.90  -11.97   -8.17   -6.21   -4.53   -0.13
## dow_effect[2]   -4.61    0.22 2.89  -10.29   -6.54   -4.49   -2.84    1.58
## dow_effect[3]   -4.57    0.22 2.88  -10.16   -6.42   -4.47   -2.79    1.53
## dow_effect[4]   -4.03    0.22 2.90   -9.64   -5.93   -3.91   -2.26    2.15
## dow_effect[5]   -4.09    0.22 2.89   -9.73   -5.98   -4.00   -2.35    2.06
## dow_effect[6]   -4.36    0.22 2.89  -10.01   -6.22   -4.24   -2.61    1.79
## dow_effect[7]  -10.41    0.22 2.89  -16.09  -12.30  -10.31   -8.65   -4.31
## lp__          -446.24    0.08 2.47 -451.88 -447.69 -445.87 -444.45 -442.44
##               n_eff Rhat
## sigma           896 1.00
## qtr_effect[1]   171 1.02
## qtr_effect[2]   170 1.02
## qtr_effect[3]   171 1.02
## qtr_effect[4]   170 1.02
## dow_effect[1]   173 1.02
## dow_effect[2]   171 1.02
## dow_effect[3]   172 1.02
## dow_effect[4]   172 1.02
## dow_effect[5]   174 1.02
## dow_effect[6]   173 1.02
## dow_effect[7]   171 1.02
## lp__            910 1.01
## 
## Samples were drawn using NUTS(diag_e) at Mon Feb 05 09:51:59 2018.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>You’ll notice the model is starting to have a harder time, with Rhat = 1.01 for all the effects. This model is perfectly ok, for the most part (look at the <code>mcmc_trace</code>!), but we’ll talk next time about a subtle issue with it (and one I easily swept under the rug earlier when adding a quarter effect). Hint: it had to do with a previous iteration of this post I talked about above.</p>
<div id="discussion" class="section level2">
<h2>Discussion</h2>
<p>After having introduced the Greenville flight data, a simple model for analysis, and how to analyze output, we discussed how to exploit some of the structure in the data, specifically the fact that airlines tend to run flights by seasons and day of week. We saw how this manifested in the Stan code, working from the <code>model</code> block back to the <code>data</code> block. But there are storm clouds on the horizon, as we started getting some curious results and some more difficulty with convergence.</p>
</div>
</div>
